{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "The Chesapeake Bay Program [DataHub](https://datahub.chesapeakebay.net/Home) contains many datasets for the Chesapeake Bay. \n",
    "\n",
    "The Water Quality Data is still updating and measures many field and lab parameters including: phosphorus, nitrogen, carbon, various other lab parameters (suspended solids, disolved solids, chlorophyll-a, alkalinkity, etc), dissolved oxygen, pH, salinity, turbitity, water temperature, and climate condition. See [Guide to Using Chesapeake Bay Program Water Quality Monitoring Data](https://d18lev1ok5leia.cloudfront.net/chesapeakebay/documents/wq_data_userguide_10feb12_mod.pdf) for more information.\n",
    "\n",
    "There is also a [DataHub API](https://datahub.chesapeakebay.net/API) which we will used to access the data from July 29, 2004 through July 29, 2024. It is a lot of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rl/kqt6tbv90l9_pwc4927vdb340000gn/T/ipykernel_83404/3917417675.py:1: DtypeWarning: Columns (25,30,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  water = pd.read_csv('../../data/plank_ChesapeakeWaterQuality.csv')\n"
     ]
    }
   ],
   "source": [
    "water = pd.read_csv('../../data/plank_ChesapeakeWaterQuality.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I forgot to set the index to false, and this is already a big file. Let's just drop that column. Also, `BiasPC` only has a value in one row, so lets drop that. `FieldActivityEventType` is only in 6 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = water.drop(columns=[water.columns[0],'BiasPC','FieldActivityEventType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing columns and creating dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what columns are we have and some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CBSeg2003', 'EventId', 'Cruise', 'Program', 'Project', 'Agency',\n",
       "       'Source', 'Station', 'SampleDate', 'SampleTime', 'TotalDepth',\n",
       "       'UpperPycnocline', 'LowerPycnocline', 'Depth', 'Layer', 'SampleType',\n",
       "       'SampleReplicateType', 'Parameter', 'Qualifier', 'MeasureValue', 'Unit',\n",
       "       'Method', 'Lab', 'Problem', 'Details', 'Latitude', 'Longitude',\n",
       "       'TierLevel', 'AirTemp', 'WindSpeed', 'WindDirection', 'PrecipType',\n",
       "       'TideStage', 'WaveHeight', 'CloudCover'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2173439, 35)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a dictionary between the parameters and their units. We will manually create the initial dictionary between the parameter and its meaning, since they are in a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHLA' 'DIN' 'DO' 'DON' 'DOP' 'KD' 'NH4F' 'NO23F' 'NO2F' 'NO3F' 'PC' 'PH'\n",
      " 'PHEO' 'PN' 'PO4F' 'PP' 'SALINITY' 'SECCHI' 'SIF' 'SIGMA_T' 'SPCOND'\n",
      " 'TDN' 'TDP' 'TN' 'TON' 'TP' 'TSS' 'WTEMP' 'VSS' nan 'DOC' 'PIP' 'FSS'\n",
      " 'TURB_NTU' 'DO_SAT_P']\n"
     ]
    }
   ],
   "source": [
    "water_parameters = water['Parameter'].unique()\n",
    "\n",
    "print(water_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial dictionary with parameter and its meaning\n",
    "param_to_meaning = {'CHLA': 'Chlorophyll-a', \n",
    "                    'DIN': 'Dissolved inorganic nitrogen', \n",
    "                    'DO': 'Dissolved oxygen', \n",
    "                    'DON': 'Dissolved organic nitrogen', \n",
    "                    'DOP': 'Dissolved organic phosphorus',\n",
    "                    'KD': 'Light attenuation',\n",
    "                    'NH4F': 'Ammonium (filtered)',\n",
    "                    'NO23F': 'Nitrite + nitrate (filtered)',\n",
    "                    'NO2F': 'Nitrite ( filtered)', 'NO3F': 'Nitrite ( filtered)',\n",
    "                    'PC': 'Particulate organic carbon',\n",
    "                    'PH' : 'pH','PHEO': 'pheophytin',\n",
    "                    'PN': 'Particulate Organic Nitrogen and Particulate Nitrogen', \n",
    "                    'PO4F': 'Orthophosphorus (filtered)', 'PP': 'Particulate phosphorus','SALINITY': 'Salinity', \n",
    "                    'SECCHI': 'Secchi disk depth',\n",
    "                    'SIF': 'Silica (filtered)', \n",
    "                    'SIGMA_T': 'Specific gravity',\n",
    "                    'SPCOND': 'Specific conductivity',\n",
    "                    'TDN': 'Total dissolved nitrogen',\n",
    "                    'TDP': 'Total dissolved phosphorus', \n",
    "                    'TN': 'Total nitrogen',\n",
    "                    'TON': 'Total organic nitrogen',\n",
    "                    'TP': 'Total phosphorus',\n",
    "                    'TSS': 'Total suspended solids', \n",
    "                    'WTEMP': 'Water temperature',\n",
    "                    'VSS': '?',\n",
    "                    'DOC': 'Dissolved organic carbon',\n",
    "                    'PIP': 'Particulate phosphorus',\n",
    "                    'FSS': 'Fixed suspended solids','TURB_NTU': 'Turbidity: nephelometric method',\n",
    "                    'DO_SAT_P' : 'Dissolved oxygen relative To theoretical value At saturation'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary for meaning and units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_param_dict = {param: {'Units': unit, 'Type': \"\"} for param, unit in zip(water['Parameter'], water['Unit'])}\n",
    "\n",
    "# Update the dictionary with the meanings\n",
    "for param in water_param_dict:\n",
    "    if param in param_to_meaning:\n",
    "        water_param_dict[param]['Type'] = param_to_meaning[param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = water.drop(columns='Unit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add to the JSON dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from JSON file\n",
    "with open('../../data/plank_CBPparam_dict.json', 'r') as f:\n",
    "    benthic_param_dict = json.load(f)\n",
    "\n",
    "new_param_dict = {**benthic_param_dict, **water_param_dict}\n",
    "\n",
    "with open('../../data/plank_CBPparam_dict.json', 'w') as f:\n",
    "    json.dump(new_param_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn parameters into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_to_columns(dataframe,columns_to_group):\n",
    "    # Reset index to use row numbers as the index\n",
    "    df_reset = dataframe.reset_index(drop=True)\n",
    "\n",
    "    # Pivot the DataFrame while preserving non-pivoted columns\n",
    "    df_pivoted = df_reset.pivot_table(index=df_reset.index, columns='Parameter', values='MeasureValue', aggfunc='first')\n",
    "\n",
    "    # Combine pivoted result with the original DataFrame columns not involved in the pivot\n",
    "    df_pivoted = df_reset.drop(columns=['Parameter','MeasureValue']).join(df_pivoted)\n",
    "    \n",
    "    # Create a copy of the DataFrame for processing\n",
    "    df_processed = df_pivoted.copy()\n",
    "\n",
    "    # Create a unique identifier for each group based on the columns to match\n",
    "    df_processed['UniqueID'] = df_processed[columns_to_group].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "    # Group by the unique identifier\n",
    "    df_combined = df_processed.groupby('UniqueID', as_index=False).first()\n",
    "\n",
    "    # Drop the UniqueID column and remove duplicates\n",
    "    df_clean = df_combined.drop(columns='UniqueID').drop_duplicates()\n",
    "\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the columns to group by calling the APi for one year of monitoring data. Some of the columns were empty, so we will intersect the monitor data columns with our water data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_data = pd.read_csv('https://datahub.chesapeakebay.net/api.CSV/WaterQuality/MonitorEvent/8-5-2023/8-6-2024/2,4,6/12,13,15,35,36,2,3,7,33,34,23,24/CBSeg2003/10,11,12,13,14,15,16,17,28,49,84')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_group = monitor_data.columns.intersection(water.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_clean = parameter_to_columns(water,columns_to_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how big the dataframe is now!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39490, 66)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20140"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_clean['EventId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_clean.to_csv('../../data/plank_ChesapeakeWaterQuality_pivoted.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
